{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constructs script for allignment to H99 Reference genome.\n",
    "## uses SAMTOOLS and FREEBAYES\n",
    "## Collect the progeny fastq names\n",
    "## Set local directories and pahts.\n",
    "## These include local dir and file names on Magwene lab machines\n",
    "## and will need to augmented for use elsewhere\n",
    "## Construct variables using data on local machine\n",
    "\n",
    "## Import needed modules. \n",
    "import os, pandas as pd, numpy as np\n",
    "#from os import listdir\n",
    "#from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gather current working directories\n",
    "scriptsdir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chr14', 'Chr13', 'Chr12', 'Chr11', 'Chr10']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load in reference file and parese out contig names\n",
    "## Set path to reference\n",
    "ref_file_path = '../DATA/H99_latest_Vikas_assembly.fasta'\n",
    "\n",
    "## open file parse lines\n",
    "pb = [line for line in open(ref_file_path,'r').readlines()]\n",
    "\n",
    "## Check work\n",
    "assert len(pb) > 0, \"Missing reference file and contents.\"\n",
    "\n",
    "## Gather contig names\n",
    "contig_names = [l[1:-1] for l in pb if l[0] == '>']\n",
    "\n",
    "## Check length and print 5 contig names.\n",
    "assert len(contig_names) >= 14, \"Missing a contig!\"\n",
    "contig_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56,\n",
       " ['Bt65F1prog44_S63_L006_R1_001.fastq.gz',\n",
       "  'Bt65F1prog44_S63_L006_R2_001.fastq.gz',\n",
       "  'Bt65F1prog8_S54_L006_R1_001.fastq.gz',\n",
       "  'Bt65F1prog8_S54_L006_R2_001.fastq.gz'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load in list of fast q files used in analysis\n",
    "bts = [l.split('\\n')[0] for l in open('../DATA/Progeny_FASTQS.csv','r').readlines()]\n",
    "\n",
    "## Print length and names of files\n",
    "len(bts), bts[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([37, 39, 41, 44]), 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Gather progeny integer names\n",
    "prog_int = np.unique([int(b.split('prog')[-1].split('_S')[0]) for b in bts])\n",
    "\n",
    "## Print a few four and len\n",
    "prog_int[-4:], len(prog_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gather progeny names\n",
    "progs = sorted(np.unique([b.split('R')[0] for b in bts]))\n",
    "\n",
    "## Check work\n",
    "assert len(progs) == len(prog_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R1_001.fastq.gz', 'R2_001.fastq.gz'], dtype='<U15')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Gather file ends of fastqs\n",
    "file_ends = np.unique(['R'+b.split('R')[-1] for b in bts])\n",
    "\n",
    "## Check work\n",
    "assert len(file_ends) == 2, \"Error, fastq files are not paired, check files.\"\n",
    "\n",
    "## Print file end\n",
    "file_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write variables \n",
    "## These vairalbes will include paths to files and executables on Haraka\n",
    "## File names\n",
    "my_h99_align = '/Crypto-HM-H99-aln-pe-sam.sh' #1st in pipeline\n",
    "my_sam_to_bam = '/Crypto-HM-H99-Bio-sam-to-sorted-bam.sh' # 2nd in pipeline\n",
    "my_bamaddrg = '/Crypto-HM-H99-Bio-bamaddrg.sh' # 3rd in pipeline\n",
    "myfreebay = ['/Crypto-HM-H99-Bio-freebayes1.sh',\n",
    "             '/Crypto-HM-H99-Bio-freebayes2.sh',\n",
    "             '/Crypto-HM-H99-Bio-freebayes3.sh'] # 4th in pipeline\n",
    "\n",
    "## List of sorted bam files with read group info. \n",
    "mybamsrg = '/Crypto-HM-H99-list-sort-bams-rg.txt'\n",
    "\n",
    "## Script directory \n",
    "duck_SCRIPTS = '/bigscratch0/croth/HYPERMUTATOR/Hypermutator/SCRIPTS'\n",
    "duck_VCF = '/bigscratch0/croth/HYPERMUTATOR/Hypermutator/VCFs/H99'\n",
    "\n",
    "## duckydog paths\n",
    "duck_SHEBANG = '#!/bin/bash\\n'\n",
    "\n",
    "## Reference\n",
    "duck_REF = '/bigscratch0/croth/HYPERMUTATOR/Hypermutator/REFs/%s'%(ref_file_path.split('/')[-1])\n",
    "\n",
    "## QTL raw fastq file directory \n",
    "duck_QTL_RAW = '/bigscratch0/croth/HYPERMUTATOR/Hypermutator/Priest_4915_180622A1'\n",
    "\n",
    "## SAMS and BAMS directories \n",
    "duck_SAMS = '/bigscratch0/croth/HYPERMUTATOR/Hypermutator/SAM/H99/'\n",
    "duck_BAMS = '/bigscratch0/croth/HYPERMUTATOR/Hypermutator/BAM/H99/'\n",
    "\n",
    "## commands\n",
    "duck_BWA = 'bwa mem -v 0 ' + duck_REF\n",
    "\n",
    "## Upload these files to and make executable via chmod, e.g. \"chmod +x Crypto-DNX-Pac_Bio_align.sh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Align\n",
    "## Open and write script for aligning reads\n",
    "f = open(scriptsdir+my_h99_align,'w') ## open file with samples to be remapped (b/c of their corrected parttners)\n",
    "print(duck_SHEBANG,file=f) ## print the shebang\n",
    "sams = []\n",
    "for seg in progs:\n",
    "    print(duck_BWA, ## print the bwa command and reference genome\n",
    "          duck_QTL_RAW+ '/'+seg+file_ends[0], ## the first read in pair file \n",
    "          duck_QTL_RAW + '/'+seg+file_ends[1],'>', ## the second\n",
    "          duck_SAMS+seg+duck_REF.split('/')[-1].split('.')[0]+'-aln-pe.sam\\n', ## The final sam file\n",
    "        file=f) ## tells print which file to print to. Que clever ;)\n",
    "    sams.append(duck_SAMS+seg+duck_REF.split('/')[-1].split('.')[0]+'-aln-pe.sam')\n",
    "f.close() ## close the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/bigscratch0/croth/HYPERMUTATOR/Hypermutator/SAM/H99/Bt65F1prog11_S64_L006_H99_latest_Vikas_assembly-aln-pe.sam',\n",
       " '/bigscratch0/croth/HYPERMUTATOR/Hypermutator/SAM/H99/Bt65F1prog12_S39_L005_H99_latest_Vikas_assembly-aln-pe.sam',\n",
       " '/bigscratch0/croth/HYPERMUTATOR/Hypermutator/SAM/H99/Bt65F1prog13_S65_L006_H99_latest_Vikas_assembly-aln-pe.sam',\n",
       " '/bigscratch0/croth/HYPERMUTATOR/Hypermutator/SAM/H99/Bt65F1prog14_S66_L006_H99_latest_Vikas_assembly-aln-pe.sam',\n",
       " '/bigscratch0/croth/HYPERMUTATOR/Hypermutator/SAM/H99/Bt65F1prog17_S67_L006_H99_latest_Vikas_assembly-aln-pe.sam']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sam to Bam\n",
    "## check work\n",
    "assert len(sams) == len(prog_int), \"Missing sam files!\"\n",
    "\n",
    "## Show five file paths\n",
    "sams[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SAM to BAM conversion\n",
    "f = open(scriptsdir+my_sam_to_bam,'w') ## Open file to print text to ... \n",
    "bams = []\n",
    "print(duck_SHEBANG,file=f) ## print the shebang\n",
    "for sam in sams:\n",
    "    bam = duck_BAMS+sam.split('/')[-1].split('.')[0]+'-sorted'\n",
    "    print('samtools view -bS %s | samtools sort - %s'%(sam,bam+'\\n'),file=f) ## Make sam to bam file\n",
    "    bams.append(bam+'.bam')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/bigscratch0/croth/HYPERMUTATOR/Hypermutator/BAM/H99/Bt65F1prog11_S64_L006_H99_latest_Vikas_assembly-aln-pe-sorted.bam',\n",
       " '/bigscratch0/croth/HYPERMUTATOR/Hypermutator/BAM/H99/Bt65F1prog12_S39_L005_H99_latest_Vikas_assembly-aln-pe-sorted.bam',\n",
       " '/bigscratch0/croth/HYPERMUTATOR/Hypermutator/BAM/H99/Bt65F1prog13_S65_L006_H99_latest_Vikas_assembly-aln-pe-sorted.bam',\n",
       " '/bigscratch0/croth/HYPERMUTATOR/Hypermutator/BAM/H99/Bt65F1prog14_S66_L006_H99_latest_Vikas_assembly-aln-pe-sorted.bam',\n",
       " '/bigscratch0/croth/HYPERMUTATOR/Hypermutator/BAM/H99/Bt65F1prog17_S67_L006_H99_latest_Vikas_assembly-aln-pe-sorted.bam']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bam to Bamaddrg\n",
    "bams[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(scriptsdir+my_bamaddrg,'w') ## Open file to print text to ... \n",
    "print(duck_SHEBANG,file=f) ## print the shebang\n",
    "print('cd /bigscratch0/croth/bamaddrg\\n',file=f)\n",
    "bamsrg = []\n",
    "for bam in bams:\n",
    "    print('./bamaddrg -b %s -s %s -r %s > %s\\n'%(\n",
    "        bam,\n",
    "        bam.split('/Bt65F1')[-1].split('_L')[0],\n",
    "        bam.split('/')[-1].split('_H99')[0],\n",
    "        bam.split('.')[0]+'-rg.bam'\n",
    "    ),file=f) \n",
    "    print('rm %s\\n'%(bam),file=f)\n",
    "    print('samtools index %s %s'%(bam.split('.')[0]+'-rg.bam',## Use samtools to index bam file\n",
    "                                  bam.split('.')[0]+'-rg.bam.bai\\n'),file=f) \n",
    "    print('echo added rg to %s'%(bam.split('/')[-1].split('_H99')[0]),file=f)\n",
    "    bamsrg.append(bam.split('.')[0]+'-rg.bam')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FREEBAYES!!!!!\n",
    "## Construct commands for freebayes variant caller\n",
    "## Check work, \n",
    "assert len(bamsrg) == len(progs), \"Missing sorted BAM files\"\n",
    "\n",
    "## Print bams to file\n",
    "f = open(scriptsdir+mybamsrg,'w')\n",
    "for bam in bamsrg:\n",
    "    print(bam,file=f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split analysis of variants across chromosomes\n",
    "## Patch list of chromosomes\n",
    "chrom_map = [a for a in contig_names]\n",
    "\n",
    "## SPlit chromosomes across freebayes bash commands\n",
    "chrom_file_maps = [chrom_map[i::len(myfreebay)] for i in range(len(myfreebay))]\n",
    "\n",
    "## CHeck work\n",
    "assert len(np.unique(np.concatenate(chrom_file_maps))) == 14, \"Error in chromosome sorting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chr14\n",
      "Chr11\n",
      "Chr8\n",
      "Chr5\n",
      "Chr2\n",
      "Chr13\n",
      "Chr10\n",
      "Chr7\n",
      "Chr4\n",
      "Chr1\n",
      "Chr12\n",
      "Chr9\n",
      "Chr6\n",
      "Chr3\n"
     ]
    }
   ],
   "source": [
    "## Make and write feebayes commands\n",
    "## Iterate over freebaye bash scripts\n",
    "for i,path in enumerate(myfreebay):\n",
    "    \n",
    "    ## Gather chromosomes for analysis\n",
    "    chrom_map = chrom_file_maps[i]\n",
    "    \n",
    "    ## Open file\n",
    "    f = open(scriptsdir+path,'w')\n",
    "    \n",
    "    ## Iterate over chromosomes\n",
    "    for region in chrom_map:\n",
    "        \n",
    "        ## Write the freebayes command for this chromosome\n",
    "        print(region)\n",
    "        new_vcf = duck_VCF+'/Bt65F1prog-'+region+'-'+duck_REF.split('.fasta'\n",
    "                )[0].split('/')[-1]+'-'+str(len(bamsrg))+'.vcf'\n",
    "        freebayes = '/usr/local/bin/freebayes -f %s -p %s -r %s -L %s -= > %s'%(\n",
    "        duck_REF,str(1),region,duck_SCRIPTS+mybamsrg,new_vcf)\n",
    "        \n",
    "        print(freebayes,file=f)\n",
    "        print('gzip %s'%new_vcf,file=f)\n",
    "        print(' ',file=f)\n",
    "        \n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
